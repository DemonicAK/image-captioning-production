
import numpy as np
from tensorflow.keras.preprocessing.sequence import pad_sequences
from inference.model_loader import supermodel,wordtoix,ixtoword,max_length
from inference.preprocess import image_preprocessor

def GreedySearch(image_features):
    in_text = ['startseq']
    model=supermodel
    for _ in range(1+max_length):
        seq = [wordtoix[w] for w in in_text if w in wordtoix]
        seq = pad_sequences([seq], maxlen=max_length, padding='post')

        yhat = model.predict([image_features, seq])[0]

        next_id = np.argmax(yhat)
        next_word = ixtoword.get(next_id)

        # ðŸ”¥ stop conditions
        if next_word is None:
            break
        if next_word == 'endseq':
            break
        if next_word in in_text[-2:]:   # repetition guard
            break
        in_text.append(next_word)

    return in_text[1:]


def BeamSearch(image_features, beam_width=3):
    """
    image_features: precomputed image feature array
    beam_width: number of top sequences to keep at each step
    """
    model = supermodel
    start_seq = ['startseq']
    
    # Each element is (sequence, score)
    sequences = [(start_seq, 0.0)]
    
    for _ in range(max_length):
        all_candidates = []
        
        for seq, score in sequences:
            # Convert current seq to integer sequence
            seq_ids = [wordtoix[w] for w in seq if w in wordtoix]
            seq_ids = pad_sequences([seq_ids], maxlen=max_length, padding='post')
            
            # Predict next word probabilities
            yhat = model.predict([image_features, seq_ids], verbose=0)[0]
            
            # Get top beam_width predictions
            top_indices = np.argsort(yhat)[-beam_width:]  # highest probabilities
            
            for next_id in top_indices:
                next_word = ixtoword.get(next_id)
                if next_word is None:
                    continue
                if next_word == 'endseq':
                    all_candidates.append((seq + [next_word], score - np.log(yhat[next_id]+1e-10)))
                    continue
                if next_word in seq[-2:]:  # repetition guard
                    continue
                # Add candidate sequence
                new_score = score - np.log(yhat[next_id]+1e-10)
                all_candidates.append((seq + [next_word], new_score))
        
        # Sort all candidates by score and keep top beam_width
        sequences = sorted(all_candidates, key=lambda tup: tup[1])[:beam_width]
        
        # Stop if all sequences ended with 'endseq'
        if all(seq[-1] == 'endseq' for seq, _ in sequences):
            break
    
    # Return the sequence with the best score, without startseq/endseq
    best_seq = sequences[0][0]
    return [w for w in best_seq if w not in ['startseq', 'endseq']]



def run_caption_algo(algo_name, image_feature):
    algo_name = algo_name.lower()

    if algo_name == "greedy":
        seq = GreedySearch(image_feature)
    elif algo_name == "beam":
        seq = BeamSearch(image_feature)
    else:
        raise ValueError(f"Unknown algo_name: {algo_name}")

    return seq

def prediction_pipeline(
    image,
    algo_name="beam",
):
    
    try:
        image_feature = image_preprocessor(image)
        # Ensure correct shape: (1, FEATURE_DIM)
        if len(image_feature.shape) == 1:
            image_feature = tf.expand_dims(image_feature, axis=0)
        seq = run_caption_algo(algo_name, image_feature)
        caption= " ".join(seq)
        # Validate caption
        if caption is None or len(caption.strip()) <= 1:
            return "caption not generated by model"
        return caption

    except Exception as e:
        print("Prediction error:", e)
        return "no caption"
